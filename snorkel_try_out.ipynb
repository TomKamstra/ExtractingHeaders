{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function \n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# In this case X are the lines and y is the output (A heading = 1, No heading = 0)\n",
    "df = pd.read_csv('csvs/total_df.csv', index_col=0)\n",
    "df = df.dropna()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['parsed_line'], df['heading_bool'], test_size=0.2, random_state=42)\n",
    "df_train_splitted, df_test_splitted = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For clarity, we define constants to represent the class labels for spam, ham, and abstaining.\n",
    "TEXT = 0\n",
    "HEADER = 1\n",
    "# TODO: Later use? \n",
    "EQUATION = 2\n",
    "NOTABLE = -1\n",
    "@labeling_function()\n",
    "def contains_abstract(x):\n",
    "    # print(x)\n",
    "    try:\n",
    "        return HEADER if \"abstract\" in x.text.lower() else TEXT\n",
    "    except AttributeError:\n",
    "        return NOTABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4560/4560 [00:00<00:00, 61523.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>heading_bool</th>\n",
       "      <th>source_paper</th>\n",
       "      <th>math_bool</th>\n",
       "      <th>latin_numbered_bool</th>\n",
       "      <th>numberic_numbered_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13916</th>\n",
       "      <td>n=1exp−6∗6n\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>Language_Modeling_With_Dynamic_Bayesian_Networ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16478</th>\n",
       "      <td>better substitution generation than PPDB and S...</td>\n",
       "      <td>False</td>\n",
       "      <td>LSBert A Simple Framework for Lexical</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20737</th>\n",
       "      <td>diﬀerent conﬁgurations and customer needs. It ...</td>\n",
       "      <td>False</td>\n",
       "      <td>sbbd_shp_07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>The field of artificial intelligence (AI) in c...</td>\n",
       "      <td>False</td>\n",
       "      <td>29020-59012-1-PB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>nine of the subsets should be combined to form...</td>\n",
       "      <td>False</td>\n",
       "      <td>lfw_paper</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21422</th>\n",
       "      <td>.\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>Systematic Design of a Transimpedance Amplifier</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>with a CMRR that is not affected by inequaliti...</td>\n",
       "      <td>False</td>\n",
       "      <td>A_Broadband_High_Common_Mode_Rejection_Ratio_I...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>effectiveness of the proposed method on sentim...</td>\n",
       "      <td>False</td>\n",
       "      <td>Context-Based_Feature_Technique_for_Sarcasm_Id...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>such as AI have become useful in identifying c...</td>\n",
       "      <td>False</td>\n",
       "      <td>ijerph-18-05686-v2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19174</th>\n",
       "      <td>scribe the construction of the grid projection...</td>\n",
       "      <td>False</td>\n",
       "      <td>pub07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4560 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  heading_bool  \\\n",
       "13916                                      n=1exp−6∗6n\\n         False   \n",
       "16478  better substitution generation than PPDB and S...         False   \n",
       "20737  diﬀerent conﬁgurations and customer needs. It ...         False   \n",
       "1210   The field of artificial intelligence (AI) in c...         False   \n",
       "14582  nine of the subsets should be combined to form...         False   \n",
       "...                                                  ...           ...   \n",
       "21422                                                .\\n         False   \n",
       "3114   with a CMRR that is not affected by inequaliti...         False   \n",
       "5618   effectiveness of the proposed method on sentim...         False   \n",
       "12839  such as AI have become useful in identifying c...         False   \n",
       "19174  scribe the construction of the grid projection...         False   \n",
       "\n",
       "                                            source_paper  math_bool  \\\n",
       "13916  Language_Modeling_With_Dynamic_Bayesian_Networ...      False   \n",
       "16478              LSBert A Simple Framework for Lexical      False   \n",
       "20737                                        sbbd_shp_07      False   \n",
       "1210                                    29020-59012-1-PB      False   \n",
       "14582                                          lfw_paper      False   \n",
       "...                                                  ...        ...   \n",
       "21422    Systematic Design of a Transimpedance Amplifier      False   \n",
       "3114   A_Broadband_High_Common_Mode_Rejection_Ratio_I...      False   \n",
       "5618   Context-Based_Feature_Technique_for_Sarcasm_Id...      False   \n",
       "12839                                 ijerph-18-05686-v2      False   \n",
       "19174                                              pub07      False   \n",
       "\n",
       "       latin_numbered_bool  numberic_numbered_bool  \n",
       "13916                False                    True  \n",
       "16478                False                    True  \n",
       "20737                False                    True  \n",
       "1210                 False                    True  \n",
       "14582                False                   False  \n",
       "...                    ...                     ...  \n",
       "21422                False                   False  \n",
       "3114                 False                   False  \n",
       "5618                 False                   False  \n",
       "12839                False                    True  \n",
       "19174                False                   False  \n",
       "\n",
       "[4560 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the defined labeling functions to our train data\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "# Add labeling functions to list\n",
    "lfs = [contains_abstract]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "df_train = df_train_splitted.rename(columns={'parsed_line': 'text'})\n",
    "# df_train = pd.DataFrame()\n",
    "# df_train['text'] = X_train\n",
    "# df_train['HeadingBool'] = y_train\n",
    "df_train['text'].astype(\"string\")\n",
    "df_train = df_train.dropna()\n",
    "L_train = applier.apply(df=df_train)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00328947])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_abstract = (L_train).mean(axis=0)\n",
    "coverage_abstract\n",
    "# print(f\"check coverage: {coverage_abstract * 100:.1f}%\")\n",
    "# L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contains_abstract</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "contains_abstract  0   [0, 1]       1.0       0.0        0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show some examples where a labeling function decides its a spam comment\n",
    "# After seeing this we should change the function to if the sentence starts with the word \"abstract\"\n",
    "# df_found_headers = df_train.iloc[L_train == NOTABLE]\n",
    "# correct = len(df_found_headers[df_found_headers['HeadingBool'] == 1])\n",
    "# all = len(df_found_headers)\n",
    "# print(correct/all)  \n",
    "# df_found_headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to improve it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "\n",
    "# TODO: Check if usefull\n",
    "# @labeling_function(pre=[textblob_sentiment])\n",
    "# def textblob_polarity(x):\n",
    "#     return SPAM if x.polarity > 0.9 else ABSTAIN\n",
    "  \n",
    "# @labeling_function(pre=[textblob_sentiment])\n",
    "# def textblob_subjectivity(x):\n",
    "#     return HAM if x.subjectivity >= 0.5 else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def starts_with_int_and_dot(x):\n",
    "    \"\"\"Biggest labeling functions, gets out most of the headers that start with numberic numbering'\"\"\"\n",
    "    def has_numbers(inputString):\n",
    "        return bool(re.search(r'\\d', inputString))\n",
    "    for i in range(1, 12, 1):\n",
    "        startwith_str = str(i) + \". \"\n",
    "        if x.text.lower().startswith(startwith_str) and \",\" not in x.text.lower():\n",
    "            if has_numbers(x.text.lower().split(startwith_str)[1]):\n",
    "                return TEXT\n",
    "            else:\n",
    "                return HEADER\n",
    "    return TEXT \n",
    "\n",
    "@labeling_function()\n",
    "def starts_with_latinint_and_dot(x):\n",
    "    \"\"\"Do the same for romain/latin numbering'\"\"\"\n",
    "    def has_numbers(inputString):\n",
    "        return bool(re.search(r'\\d', inputString))\n",
    "    for latin_int_str in ['I.', 'II.', 'III.', 'IV.', 'V.', 'VI.', 'VII.', 'VIII.', 'IX.', 'X.', 'XI.']:\n",
    "        startwith_str = latin_int_str\n",
    "        if x.text.startswith(startwith_str) and \",\" not in x.text:\n",
    "            return HEADER\n",
    "    return TEXT\n",
    "\n",
    "@labeling_function()\n",
    "def starts_with_latinint(x):\n",
    "    \"\"\"Do the same for romain/latin numbering without .'\"\"\"\n",
    "    def has_numbers(inputString):\n",
    "        return bool(re.search(r'\\d', inputString))\n",
    "    for latin_int_str in ['I ', 'II ', 'III ', 'IV ', 'V ', 'VI ', 'VII ', 'VIII ', 'IX ', 'X ', 'XI ']:\n",
    "        startwith_str = latin_int_str\n",
    "        if x.text.startswith(startwith_str) and \",\" not in x.text:\n",
    "            return HEADER\n",
    "    return TEXT\n",
    "\n",
    "@labeling_function()\n",
    "def start_int_look_for_words(x):\n",
    "    header_words = ['introduction', 'discussion', 'conclusion', 'i ntroduction', 'd iscussion', 'c onclusion']\n",
    "    \"\"\"Biggest labeling functions, gets out most of the headers that start with numberic numbering'\"\"\"\n",
    "    def has_numbers(inputString):\n",
    "        return bool(re.search(r'\\d', inputString))\n",
    "    for i in range(1, 12, 1):\n",
    "        startwith_str = str(i) + \" \"\n",
    "        if x.text.lower().startswith(startwith_str) and \",\" not in x.text.lower():\n",
    "            for header_word in header_words:\n",
    "                if header_word in x.text.lower().split(startwith_str)[1]:\n",
    "                    return HEADER\n",
    "    return TEXT \n",
    "    \n",
    "\n",
    "# @labeling_function()\n",
    "# def starts_with_romainInt_and_dot(x):\n",
    "#     \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
    "#     try:\n",
    "#         return HEADER if x.text.lower().startswith(\"I. \") else TEXT\n",
    "#     except AttributeError:\n",
    "#         return NOTABLE\n",
    "\n",
    "@labeling_function()\n",
    "def start_abstract(x):\n",
    "    try:\n",
    "        return HEADER if x.text.lower().startswith(\"abstract\\n\") or x.text.lower().startswith(\"abstract \") or x.text.lower().startswith(\"abstract-\") or x.text.lower().startswith(\"abstract.\") else TEXT\n",
    "    except AttributeError:\n",
    "        return NOTABLE\n",
    "\n",
    "# @labeling_function()\n",
    "# def start_introduction(x):\n",
    "#     try:\n",
    "#         return HEADER if x.text.lower().startswith(\"introduction\") else TEXT\n",
    "#     except AttributeError:\n",
    "#         return NOTABLE\n",
    "\n",
    "# @labeling_function() \n",
    "# def please_comment(x):\n",
    "#     return SPAM if any(word in x.text.lower() for word in ['please', 'pls', 'plz']) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4560/4560 [00:01<00:00, 2919.14it/s]\n",
      "100%|██████████| 4560/4560 [00:01<00:00, 2987.50it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test_splitted.rename(columns={'parsed_line' : 'text'})\n",
    "# df_test['text'] = X_test\n",
    "# df_test['HeadingBool'] = y_test\n",
    "df_test['text'].astype(\"string\")\n",
    "df_test = df_test.dropna()\n",
    "# lfs = [starts_with_int_and_dot, starts_with_latinint_and_dot, starts_with_romainInt_and_dot, start_abstract, start_introduction]\n",
    "lfs = [starts_with_int_and_dot, starts_with_latinint_and_dot, start_abstract, start_int_look_for_words, starts_with_latinint]\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()\n",
    "df_found_headers = df_train.iloc[L_train == HEADER]\n",
    "# # df_found_headers\n",
    "print(len(df_train[df_train['heading_bool'] == 1]))\n",
    "print(len(df_found_headers[df_found_headers['heading_bool'] == 1]))\n",
    "# df_found_headers[df_found_headers['heading_bool'] == 0]\n",
    "df_train[df_train['heading_bool'] == 1].sample(10)\n",
    "df_found_headers[df_found_headers['heading_bool'] == 0].sample(10)\n",
    "# len(df[df['heading_bool'] == 0])\n",
    "# df[df['heading_bool'] == 0]\n",
    "len(df_train[df_train['heading_bool'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=8.402]\n",
      "  8%|▊         | 38/500 [00:00<00:01, 375.22epoch/s]INFO:root:[100 epochs]: TRAIN:[loss=0.005]\n",
      " 31%|███       | 155/500 [00:00<00:00, 835.40epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.002]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.001]\n",
      " 60%|██████    | 301/500 [00:00<00:00, 1043.63epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.001]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1037.23epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Train the Snorkel Label Model (Noisy Labels as Input)\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy:     98.2%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Label Model Performance\n",
    "label_model_acc = label_model.score(L=L_test, Y=y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for model training\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "#Use only training data for which labels have been created\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train instances: 66732\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of train instances: {X_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16320/2661278983.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreds_train_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\TomK2\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\TomK2\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_validate_y\u001b[1;34m(self, y, sample_weight)\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[0mn_trim_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_trim_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1272\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1273\u001b[0m                 \u001b[1;34m\"y contains %d class after sample_weight \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m                 \u001b[1;34m\"trimmed classes with zero weights, while a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
     ]
    }
   ],
   "source": [
    "#Train a simple regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier().fit(X=X_train, y=preds_train_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.2%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {gb_model.score(X=X_test, y=y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62e6f39559acf044108bd380a052a7c30f8343a1f9faabb79081e563102301ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
