Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pages 1148‚Äì1153
Florence, Italy, July 28 - August 2, 2019. c2019 Association for Computational Linguistics1148Complex Word IdentiÔ¨Åcation as a Sequence Labelling Task
Sian Gooding
Dept of Computer Science and Technology
University of Cambridge
shg36@cam.ac.ukEkaterina Kochmar
ALTA Institute
University of Cambridge
ek358@cam.ac.uk
Abstract
Complex Word IdentiÔ¨Åcation (CWI) is con-
cerned with detection of words in need of sim-
pliÔ¨Åcation and is a crucial Ô¨Årst step in a sim-
pliÔ¨Åcation pipeline. It has been shown that re-
liable CWI systems considerably improve text
simpliÔ¨Åcation. However, most CWI systems to
date address the task on a word-by-word basis,
not taking the context into account. In this pa-
per, we present a novel approach to CWI based
on sequence modelling. Our system is capa-
ble of performing CWI in context, does not
require extensive feature engineering and out-
performs state-of-the-art systems on this task.
1 Introduction
Lexical complexity is one of the main aspects con-
tributing to overall text complexity (Dubay, 2004).
It is typically addressed with lexical simpliÔ¨Åcation
(LS) systems that aim to paraphrase and substitute
complex terms for simpler alternatives. Previous
research has shown that Complex Word IdentiÔ¨Å-
cation (CWI) considerably improves lexical sim-
pliÔ¨Åcation (Shardlow, 2014; Paetzold and Specia,
2016a). This is achieved by identifying complex
terms in text prior to word substitution. The per-
formance of a CWI component is crucial, as low
recall of this component might result in an overly
difÔ¨Åcult text with many missed complex words,
while low precision might result in meaning dis-
tortions with an LS system trying to unnecessarily
simplify non-complex words (Shardlow, 2013).
CWI has recently attracted attention as a stand-
alone application, with at least two shared tasks
focusing on it. Current approaches to CWI, in-
cluding state-of-the-art systems, have a number of
limitations. First of all, CWI systems typically ad-
dress this task on a word-by-word basis, using a
large number of features to capture the complexity
of a word. For instance, the CWI system by Paet-
zold and Specia (2016c) uses a total of 69features,while the one by Gooding and Kochmar (2018)
uses 27features. Secondly, systems performing
CWI in a static manner are unable to take the con-
text into account, thus failing to predict word com-
plexity for polysemous words as well as words in
various metaphorical or novel contexts. For in-
stance, consider the following two contexts of the
word molar from the CWI 2018 shared task (Yi-
mam et al., 2018). Molar has been annotated as
complex in the Ô¨Årst context (resulting in the bi-
nary annotation of 1) by 17out of 20annotators
(thus, the ‚Äúprobabilistic‚Äù label of 0:85), and as
non-complex (label 0) in the second context:
Contexts Bin Prob
Elephants have four molars ...1 0.85
... new molars emerge in the
back of the mouth.0 0.00
The annotators may have found the second con-
text simpler on the whole, as molars is surrounded
by familiar words that imply the meaning (e.g.,
mouth ), whereas elephants is a rarer and less se-
mantically similar co-occurrence. Such context-
related effects are hard to capture with a CWI sys-
tem that only takes word-level features into ac-
count. Thirdly, CWI systems that only look at in-
dividual words cannot grasp complexity above the
word level, for example, when a whole phrase is
considered complex.
In this paper, we apply a novel approach to the
CWI, based on sequence labelling.1We show that
our system is capable of:
taking word context into account;
relying on word embeddings only, thus elim-
inating the need for extensive feature engi-
neering;
detecting both complex words and phrases;
1Trained models are available at: https://github.
com/siangooding/cwi1149not requiring genre-speciÔ¨Åc training and rep-
resenting a one-model-Ô¨Åts-all approach.
2 Related Work
2.1 Complex Word IdentiÔ¨Åcation
Early studies on CWI address this task by ei-
ther attempting to simplify all words (Thomas and
Anderson, 2012; Bott et al., 2012) or setting a
frequency-based threshold (Zeng et al., 2005; El-
hadad, 2006; Biran et al., 2011). Horn et al.
(2014) show that the former approach may miss
up to one third of complex words due to its in-
ability to Ô¨Ånd simpler alternatives, and Shard-
low (2013) argues that a simplify-all approach
might result in meaning distortions, but the more
resource-intensive threshold-based approach does
not necessarily perform signiÔ¨Åcantly better either.
At the same time, Shardlow (2013) shows that a
classiÔ¨Åcation-based approach to CWI is the most
promising one. Most of the teams participating in
the recent CWI shared tasks also use classiÔ¨Åcation
approaches with extensive feature engineering.
The Ô¨Årst shared task on CWI at SemEval
2016 (Paetzold and Specia, 2016b) used data
from several simpliÔ¨Åcation datasets, annotated by
non-native speakers. In this data, about 3%of
word types and 11% of word tokens, if contexts
are taken into account, are annotated as com-
plex (Paetzold and Specia, 2016b). The CWI 2018
shared task (Yimam et al., 2018) used the data
from Wikipedia, news sources and unprofession-
ally written news, derived from the dataset of Yi-
mam et al. (2017). The dataset was annotated by
10native and 10non-native speakers, and, de-
pending on the source of the data, contains 40%
to50% words labelled as complex in context. The
dataset contains words and phrases with two labels
each. The Ô¨Årst label represents binary judgement
with bin=1if at least 1annotator marked the word
as complex in context, and bin=0otherwise. The
second label is a ‚Äúprobabilistic‚Äù label representing
the proportion of the 20annotators that labelled
the item as complex. The importance of context
when considering word complexity is exempliÔ¨Åed
well in this dataset, as 11:34% of items have dif-
ferent binary labels depending on the context they
are used in. When considering probabilistic anno-
tations, of the items labelled in different contexts
10:96% have at least a 5-annotator difference in
complexity score in differing contexts. The dataset
contains 104instances with a 10-annotator differ-ence between scores based on the context of the
word. For instance, suspicion has been annotated
23times:
Word Unique Max Min 
suspicion 16 0.95 0.15 0.25
Of the 23probabilistic annotations for suspicion
70% are unique. Max andmin values show the
largest difference in annotations for this word in
context, with 19annotators labelling it complex in
one scenario and only 3in another. Finally, rep-
resents the standard deviation of the probabilistic
annotations for this word.
In this paper, we use the data from the CWI
2018 shared task, which contains annotation for
both words and word sequences (called phrases in
the task), and represents three different genres of
text. We focus on the binary setting (complex vs.
non-complex) and compare our results to the win-
ning system by Gooding and Kochmar (2018).
2.2 Sequence Labelling
Sequence labelling has been applied successfully
to a number of NLP tasks that rely on contex-
tual information, such as named entity recogni-
tion, part-of-speech tagging and shallow parsing.
Within this framework, the model receives as in-
put a sequence of tokens (w1;:::;w T)and pre-
dicts a label for each token as output. Typically,
the input tokens are Ô¨Årst mapped to a distributed
vector space, resulting in a sequence of word em-
beddings (x1;:::;x T). The use of word embed-
dings allows sequence models to learn similar rep-
resentations for semantically or functionally sim-
ilar words. Recent advances to sequential model
frameworks have resulted in the models‚Äô ability to
infer representations for previously unseen words
and to share information about morpheme-level
regularities (Rei et al., 2016).
Sequence labelling models beneÔ¨Åt from the
use of long short-term memory (LSTM) units
(Gers et al., 2000), as these units can capture the
long-term contextual dependencies in natural lan-
guage. A variation of the traditional architecture,
bi-directional LSTMs (BiLSTM) (Hochreiter and
Schmidhuber, 1997), has proved highly successful
at language tasks, as it is able to consider both the
left and right contexts of a word, thus increasing
the amount of relevant information available to the
network. Similarly, the use of secondary learning
objectives can increase the number of salient fea-1150tures and access to relevant information. For ex-
ample, Rei (2017) shows that training a model to
jointly predict surrounding words incentivises the
discovery of useful features and associations that
are unlikely to be discovered otherwise.
From the perspective of CWI, it is clear that
context greatly impacts the perceived difÔ¨Åculty of
text. In this paper we investigate whether CWI can
be framed as a sequence labelling task.
3 Implementation
For our experiments, we use the English part
of the CWI datasets from Yimam et al. (2017),
which contains texts on professionally written
NEWS, amateurishly written W IKINEWS, and
WIKIPEDIA articles. The original data includes
the annotation for a selected set of content words,
which is provided alongside the full sentence and
the word span. The annotation contains both bi-
nary ( bin) and ‚Äúprobabilistic‚Äù ( prob) labels as de-
tailed in Section 2:
Sentence Word Bin Prob
They drastically... drastically 1 0.5
As the sequential model expects the complete
word context as an input, we adapt the original for-
mat by tokenizing the sentences and including the
annotation for each word token, using Cfor the
annotated complex words and phrases, and Nfor
those that are either annotated as non-complex in
the original data or not included in it (e.g., function
words), which results in the following format:
They N
drastically C
...
We opted to use a sequential architecture by Rei
(2017), as it has achieved state-of-the-art results
on a number of NLP tasks, including error detec-
tion, which is similar to CWI in that it identiÔ¨Åes
relatively rare sequences of words in context. The
design of this architecture is highly suited to the
task of CWI as: (1) the use of a BiLSTM pro-
vides contextual information from both the left
and right context of a target word; (2) the con-
text is combined with both word and character-
level representations (Rei et al., 2016); (3) this
architecture uses a language modelling objective,
which enables the model to learn better compo-
sition functions and to predict the probability of
individual words in context. As previous workon CWI has consistently found word frequency
and length to be highly informative features, we
choose an architecture which utilises sub-word in-
formation and a language modelling objective.
We use 300-dimensional GloVe embeddings as
word representations (Pennington et al., 2014) and
train the model on randomly shufÔ¨Çed texts from
all three genres for 20iterations. We train the
model using word annotations and predict binary
word scores using the output label probabilities. If
the probability of a word belonging to the com-
plex class is above 0:50, it is considered a com-
plex word. For phrase-level binary prediction, we
consider the phrases contained within the dataset.
The complex class probability for each word, aside
from stop words, is predicted and combined into a
Ô¨Ånal average score. If this average is above a pre-
deÔ¨Åned threshold of 0:50then the phrase is con-
sidered complex.
4 Results & Discussion
Results: We report the results obtained with the
sequence labelling (S EQ) model for the binary task
and compare them to the current state-of-the-art
in complex word identiÔ¨Åcation, C AMB system by
Gooding and Kochmar (2018), which achieved the
best results across all binary and two probabilis-
tic tracks in the CWI 2018 shared task (Yimam
et al., 2018). The evaluation metric reported is the
macro-averaged F1, as was used in the 2018 CWI
shared task (Yimam et al., 2018). For the binary
task, both words and phrases are considered cor-
rect if the system outputs the correct binary label.
The C AMB system considers words irrespective
of their context and relies on 27features of vari-
ous types, encoding lexical, syntactic, frequency-
based and other types of information about indi-
vidual words. The system uses Random Forests
and AdaBoost for classiÔ¨Åcation, but as Gooding
and Kochmar (2018) report, the choice of the fea-
tures, algorithm and training data depends on the
genre. In addition, phrase classiÔ¨Åcation is per-
formed using a ‚Äògreedy‚Äô approach and simply la-
belling all phrases as complex.
The results presented in Table 1 show that the
SEQsystem outperforms the C AMB system on all
three genres on the task of binary complex word
identiÔ¨Åcation. The largest performance increase
for words is on the W IKIPEDIA test set ( +3:60%).
Table 1 also shows that on the combined set
of words and phrases ( words+phrases ) the two1151Test Set Macro F-Score
CAMB SEQ
Words Only
NEWS 0.8633 0.8763 (+1.30)
WIKINEWS 0.8317 0.8540 (+2.23)
WIKIPEDIA 0.7780 0.8140 (+3.60)
Words+Phrases
NEWS 0.8736 0.8763 (+0.27)
WIKINEWS 0.8400 0.8505 (+1.05)
WIKIPEDIA 0.8115 0.8158 (+0.43)
Table 1: S EQvs. C AMB system results on words only
and on words and phrases
systems achieve similar results: the S EQmodel
beats the C AMB model only marginally, with the
largest difference of +1:05% on the W IKINEWS
data. However, it is worth highlighting that the
CAMB system does not perform any phrase clas-
siÔ¨Åcation per se and simply marks all phrases as
complex. Using the dataset statistics, we estimate
that C AMB system achieves precision of 0:64.
The S EQmodel outperforms the C AMB system,
achieving precision of 0:71.
We note that the S EQmodel is not only able to
outperform the C AMB system on all datasets for
both words only andwords+phrases , but it also
has a clear practical advantage: the only input
information it uses at run time are word embed-
dings, whereas the C AMB system requires 27fea-
tures based on a variety of sources. In addition,
the C AMB system needs to rely on individually
tailored systems to maximize the results across
datasets, whereas the S EQmodel is a ‚Äòone size
Ô¨Åts all‚Äô model that is able to work out-of-the-box
across all datasets, achieving state-of-the-art per-
formance by harnessing the power of word con-
text, embeddings and character-level morphology.
We additionally compare our results to the re-
cent work by Maddela and Xu (2018), who show
an improvement on the CWI systems with the
use of additional ‚Äòhuman-based‚Äô features. Using
an English lexicon of 15;000 words with word-
complexity ratings by human annotators, they are
able to improve the scores of the winning CWI
system from the 2016 shared task by Paetzold and
Specia (2016c), and the nearest centroid (NC) ap-
proach by Yimam et al. (2017). They report the
best F-score of 74:8on the combined CWI 2018
shared task testset, achieved using the NC ap-
proach augmented with the complexity lexicon.We note that both C AMB and our S EQmodel
achieve signiÔ¨Åcantly higher results.
Discussion : To further analyze the results
achieved by C AMB and S EQon the test sets,
we apply the McNemar statistical test (McNemar,
1947), which is comparable to the widely used
pairedt-test, and is most suitable for dichotomous
dependent variables. Table 2 presents the con-
tingency table for words only , and Table 3 for
words+phrases :
CAMB Correct CAMB Wrong
SEQCorrect a=3002 b=205
SEQWrong c=145 d=349
Table 2: Contingency table for words only
CAMB Correct CAMB Wrong
SEQCorrect a=3443 b=207
SEQWrong c=145 d=457
Table 3: Contingency table for words+phrases
Using the above values, the continuity corrected
McNemar test (Edwards, 1948) estimates 2as:
2=(jb cj 1)2
(b+c)(1)
According to the test, the S EQsystem achieves
signiÔ¨Åcantly better results than the C AMB system
onwords only (p= 0:0016 ,2= 9:95) as well as
onwords+phrases (p= 0:0011 ,2= 10:57).
349word tokens, with 289word types, are in-
correctly labelled by both systems (see Table 2).
Of these, 166words are incorrectly identiÔ¨Åed as
complex, and 183are incorrectly identiÔ¨Åed as sim-
ple. Of the words that are not identiÔ¨Åed as com-
plex by the S EQmodel, 74% are marked as com-
plex by only one annotator out of twenty, and 93%
by one or two annotators. This highlights the id-
iosyncratic nature of the task and why it may be
particularly challenging to address the complexity
needs of all individuals with a single system.
There are 205word instances that are correctly
classiÔ¨Åed by the S EQmodel, but not by the C AMB
system. 34% of these words the C AMB system
correctly classiÔ¨Åes in other contexts, but not when
the context changes, for instance when the same
words are used in unusual or metaphorical con-
texts. Table 4 presents some examples of the con-
texts where the S EQmodel correctly identiÔ¨Åes the
complexity of the word, but C AMB model fails
(LABEL stands for the gold standard label).1152Contexts CAMB SEQ LABEL
Successive waves
of bank sector
reforms have failed0 1 1
Diffraction occurs
with all waves0 0 0
Table 4: Context dependent annotations of the word
waves
We note that the S EQmodel is able to correctly
identify the complexity of the word waves when
used in different contexts. The system outputs a
score of 0:5692 for the Ô¨Årst context ( Successive
waves of bank sector [...] ) and 0:4704 for the sec-
ond ( Diffraction occurs with all waves ), reÔ¨Çecting
that the complexity level is dependent on the con-
text.
5 Conclusions
In this paper, we address the limitations of the ex-
isting CWI systems. Our S EQmodel relies on se-
quence labelling and outperforms state-of-the-art
systems with a one-model-Ô¨Åts-all approach. It is
able to take context into account and classify both
words and phrases in a uniÔ¨Åed framework, without
the need for expensive feature engineering. Our
future research will focus on the relative nature
of complexity judgements and will use the S EQ
model to predict complexity on a scale. We will
also investigate whether the S EQmodel may ben-
eÔ¨Åt from sources of information other than word
embeddings and character-level morphology. Fi-
nally, we plan to investigate alternative methods to
modelling phrase and multi-word expression com-
plexity.
Acknowledgments
We thank Cambridge English for supporting this
research via the ALTA Institute. We are also grate-
ful to the anonymous reviewers for their valuable
feedback.
References
Or Biran, Samuel Brody, and Noemie Elhadad. 2011.
Putting it Simply: a Context-Aware Approach to
Lexical SimpliÔ¨Åcation. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: short papers , pages 496‚Äì501.
Stefan Bott, Luz Rello, Biljana Drndarevic, and Hora-
cio Saggion. 2012. Can Spanish Be Simpler? Lex-SiS: Lexical SimpliÔ¨Åcation for Spanish. In Pro-
ceedings of COLING 2012: Technical Papers , pages
357‚Äì374.
William H. Dubay. 2004. The Principles of Readabil-
ity.Costa Mesa, CA: Impact Information .
Allen L. Edwards. 1948. Note on the correction for
continuity in testing the signiÔ¨Åcance of the differ-
ence between correlated proportions. Psychome-
trika , 13(3):185‚Äì187.
Noemie Elhadad. 2006. Comprehending Technical
Texts: Predicting and DeÔ¨Åning Unfamiliar Terms.
InAMIA Annual Symposium Proceedings , pages
239‚Äì243.
Felix A. Gers, J ¬®urgen Schmidhuber, and Fred Cum-
mins. 2000. Learning to forget: Continual
prediction with LSTM. Neural Computation ,
12(10):2451‚Äì2471.
Sian Gooding and Ekaterina Kochmar. 2018. CAMB at
CWI Shared Task 2018: Complex Word IdentiÔ¨Åca-
tion with Ensemble-Based V oting. In Proceedings
of the Thirteenth Workshop on Innovative Use of
NLP for Building Educational Applications , pages
184‚Äì194.
Sepp Hochreiter and J ¬®urgen Schmidhuber. 1997.
Long short-term memory. Neural computation ,
9(8):1735‚Äì1780.
Colby Horn, Cathryn Manduca, and David Kauchak.
2014. Learning a lexical simpliÔ¨Åer using Wikipedia.
InProceedings of the 52nd ACL , pages 458‚Äì463.
Mounica Maddela and Wei Xu. 2018. A Word-
Complexity Lexicon and A Neural Readability
Ranking Model for Lexical SimpliÔ¨Åcation. In Pro-
ceedings of the 2018 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP) ,
pages 3749‚Äì3760.
Quinn McNemar. 1947. Note on the sampling error
of the difference between correlated proportions or
percentages. Psychometrika , 12(2):153‚Äì157.
Gustavo Paetzold and Lucia Specia. 2016a.
PLUMBErr: An Automatic Error IdentiÔ¨Åca-
tion Framework for Lexical SimpliÔ¨Åcation. In
Proceedings of the Ô¨Årst international workshop
on Quality Assessment for Text SimpliÔ¨Åcation
(QATS) , pages 1‚Äì9. European Language Resources
Association (ELRA).
Gustavo Paetzold and Lucia Specia. 2016b. SemEval
2016 Task 11: Complex Word IdentiÔ¨Åcation. In Pro-
ceedings of the 10th International Workshop on Se-
mantic Evaluation (SemEval-2016) , pages 560‚Äì569.
Gustavo Paetzold and Lucia Specia. 2016c. SV000gg
at SemEval-2016 Task 11: Heavy Gauge Complex
Word IdentiÔ¨Åcation with System V oting. In Pro-
ceedings of the 10th International Workshop on Se-
mantic Evaluation (SemEval-2016) , pages 969‚Äì974.1153Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. GloVe: Global Vectors for Word
Representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP) , pages 1532‚Äì1543.
Marek Rei. 2017. Semi-supervised multitask learn-
ing for sequence labeling. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers) , pages
2121‚Äì2130.
Marek Rei, Gamal K.O. Crichton, and Sampo Pyysalo.
2016. Attending to characters in neural sequence
labeling models. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers , pages 309‚Äì318.
Matthew Shardlow. 2013. A Comparison of Tech-
niques to Automatically Identify Complex Words.
InProceedings of the Student Research Workshop at
the 51st Annual Meeting of the Association for Com-
putational Linguistics (ACL) , pages 103‚Äì109.
Matthew Shardlow. 2014. Out in the open: Finding
and categorising errors in the lexical simpliÔ¨Åcation
pipeline. In In Proceedings of the 9th LREC , pages
1583‚Äì1590.
S. Rebecca Thomas and Sven Anderson. 2012.
WordNet-Based Lexical SimpliÔ¨Åcation of a Docu-
ment. In Proceedings of KONVENS 2012 (Main
track: oral presentations) .
Seid Muhie Yimam, Chris Biemann, Shervin Mal-
masi, Gustavo Paetzold, Lucia Specia, Sanja ÀáStajner,
Ana¬®ƒ±s Tack, and Marcos Zampieri. 2018. A Report
on the Complex Word IdentiÔ¨Åcation Shared Task
2018. In Proceedings of the 13th Workshop on In-
novative Use of NLP for Building Educational Ap-
plications , pages 66‚Äì78.
Seid Muhie Yimam, Sanja ÀáStajner, Martin Riedl, and
Chris Biemann. 2017. CWIG3G2 - Complex Word
IdentiÔ¨Åcation Task across Three Text Genres and
Two User Groups. In Proceedings of the Eighth In-
ternational Joint Conference on Natural Language
Processing (Volume 2: Short Papers) , pages 401‚Äì
407.
Qing Zeng, Eunjung Kim, Jon Crowell, and Tony
Tse. 2005. Biological and Medical Data Analy-
sis. ISBMDA 2005. Lecture Notes in Computer Sci-
ence, volume 3745 of ISBMDA 2005 , chapter A
Text Corpora-Based Estimation of the Familiarity of
Health Terminology. Springer, Berlin, Heidelberg.